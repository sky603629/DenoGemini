import { OpenAIRequest } from "./types/openai.ts";
import { configManager, logger } from "./config/env.ts";
import { modelService } from "./services/modelService.ts";
import { geminiClient } from "./services/geminiClient.ts";
import { transformOpenAIRequestToGemini } from "./transformers/openaiToGemini.ts";
import { transformGeminiResponseToOpenAI, transformGeminiErrorToOpenAI } from "./transformers/geminiToOpenAI.ts";
import { createGeminiToOpenAISSEStream } from "./transformers/streamTransformer.ts";
import { authenticateRequest, createAuthErrorResponse } from "./middleware/auth.ts";
import { imageCache } from "./services/imageCache.ts";

async function handler(req: Request): Promise<Response> {
  const url = new URL(req.url);

  // å¤„ç†CORSé¢„æ£€è¯·æ±‚
  if (req.method === "OPTIONS") {
    return new Response(null, {
      status: 204,
      headers: getCorsHeaders(),
    });
  }

  try {
    // è·¯ç”±å¤„ç†
    if (url.pathname === "/") {
      const cacheStats = imageCache.getStats();
      return new Response(
        JSON.stringify({
          message: "Geminiåˆ°OpenAIå…¼å®¹APIæœåŠ¡å™¨",
          version: "1.0.0",
          endpoints: [
            "GET /v1/models - åˆ—å‡ºå¯ç”¨æ¨¡å‹",
            "POST /v1/chat/completions - èŠå¤©è¡¥å…¨ï¼ˆå…¼å®¹OpenAIï¼‰"
          ],
          cache: {
            images: cacheStats.size,
            totalSize: `${cacheStats.totalSize}KB`
          }
        }),
        {
          status: 200,
          headers: {
            "Content-Type": "application/json",
            ...getCorsHeaders()
          },
        }
      );
    }

    if (req.method === "GET" && url.pathname === "/v1/models") {
      return await handleModelsRequest(req);
    }

    if (req.method === "POST" && url.pathname === "/v1/chat/completions") {
      return await handleChatCompletions(req);
    }

    // æœªçŸ¥ç«¯ç‚¹è¿”å›404
    return new Response(
      JSON.stringify({ error: { message: "æœªæ‰¾åˆ°", type: "invalid_request_error" } }),
      {
        status: 404,
        headers: {
          "Content-Type": "application/json",
          ...getCorsHeaders()
        },
      }
    );

  } catch (error) {
    logger.error("è¯·æ±‚å¤„ç†å™¨ä¸­çš„æœªå¤„ç†é”™è¯¯:", error);
    return new Response(
      JSON.stringify({
        error: {
          message: "å†…éƒ¨æœåŠ¡å™¨é”™è¯¯",
          type: "api_error",
        },
      }),
      {
        status: 500,
        headers: {
          "Content-Type": "application/json",
          ...getCorsHeaders()
        },
      }
    );
  }
}

async function handleModelsRequest(req: Request): Promise<Response> {
  const requestId = `models_${Date.now()}_${Math.random().toString(36).slice(2, 11)}`;

  logger.info(`[${requestId}] ğŸ“‹ æ”¶åˆ°æ¨¡å‹åˆ—è¡¨è¯·æ±‚`);

  // éªŒè¯èº«ä»½
  const authResult = authenticateRequest(req);
  if (!authResult.success) {
    logger.warn(`[${requestId}] ğŸ”’ èº«ä»½éªŒè¯å¤±è´¥`);
    return createAuthErrorResponse(authResult);
  }

  logger.info(`[${requestId}] âœ… èº«ä»½éªŒè¯æˆåŠŸ`);

  try {
    logger.info(`[${requestId}] ğŸ“¤ è·å–æ¨¡å‹åˆ—è¡¨`);
    const models = await modelService.getOpenAICompatibleModels();
    logger.info(`[${requestId}] âœ… æˆåŠŸè·å– ${models.data?.length || 0} ä¸ªæ¨¡å‹`);

    return new Response(JSON.stringify(models), {
      status: 200,
      headers: {
        "Content-Type": "application/json",
        ...getCorsHeaders()
      },
    });
  } catch (error) {
    logger.error(`[${requestId}] âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥:`, error);
    return new Response(
      JSON.stringify({
        error: {
          message: "è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥",
          type: "api_error",
        },
      }),
      {
        status: 500,
        headers: {
          "Content-Type": "application/json",
          ...getCorsHeaders()
        },
      }
    );
  }
}

async function handleChatCompletions(req: Request): Promise<Response> {
  const requestId = `req_${Date.now()}_${Math.random().toString(36).slice(2, 11)}`;

  logger.info(`[${requestId}] ğŸ“¥ æ”¶åˆ°èŠå¤©è¡¥å…¨è¯·æ±‚`);

  // éªŒè¯èº«ä»½
  const authResult = authenticateRequest(req);
  if (!authResult.success) {
    logger.warn(`[${requestId}] ğŸ”’ èº«ä»½éªŒè¯å¤±è´¥`);
    return createAuthErrorResponse(authResult);
  }

  logger.info(`[${requestId}] âœ… èº«ä»½éªŒè¯æˆåŠŸ`);

  try {
    const openaiRequest: OpenAIRequest = await req.json();

    // è¯¦ç»†è®°å½•è¯·æ±‚ä¿¡æ¯
    logger.info(`[${requestId}] ğŸ“‹ è¯·æ±‚è¯¦æƒ…:`);
    logger.info(`[${requestId}]   - æ¨¡å‹: ${openaiRequest.model}`);
    logger.info(`[${requestId}]   - æ¶ˆæ¯æ•°é‡: ${openaiRequest.messages?.length || 0}`);
    logger.info(`[${requestId}]   - æµå¼æ¨¡å¼: ${openaiRequest.stream ? 'æ˜¯' : 'å¦'}`);
    logger.info(`[${requestId}]   - æœ€å¤§Token: ${openaiRequest.max_tokens || 'æœªè®¾ç½®'}`);
    logger.info(`[${requestId}]   - æ¸©åº¦: ${openaiRequest.temperature || 'æœªè®¾ç½®'}`);

    // åˆ†ææ¶ˆæ¯å†…å®¹
    if (openaiRequest.messages) {
      for (let i = 0; i < openaiRequest.messages.length; i++) {
        const msg = openaiRequest.messages[i];
        logger.info(`[${requestId}]   - æ¶ˆæ¯${i + 1}: ${msg.role}`);

        if (typeof msg.content === 'string') {
          const preview = msg.content.length > 100 ? msg.content.slice(0, 100) + '...' : msg.content;
          logger.info(`[${requestId}]     å†…å®¹: "${preview}"`);
        } else if (Array.isArray(msg.content)) {
          logger.info(`[${requestId}]     å¤šæ¨¡æ€å†…å®¹: ${msg.content.length} ä¸ªéƒ¨åˆ†`);
          for (let j = 0; j < msg.content.length; j++) {
            const part = msg.content[j];
            if (part.type === 'text') {
              const preview = part.text && part.text.length > 50 ? part.text.slice(0, 50) + '...' : part.text;
              logger.info(`[${requestId}]       ${j + 1}. æ–‡æœ¬: "${preview}"`);
            } else if (part.type === 'image_url') {
              const url = part.image_url?.url || '';
              if (url.startsWith('data:')) {
                const mimeMatch = url.match(/^data:([^;]+)/);
                const mimeType = mimeMatch ? mimeMatch[1] : 'æœªçŸ¥';
                const sizeKB = Math.round(url.length * 0.75 / 1024); // ä¼°ç®—å¤§å°
                logger.info(`[${requestId}]       ${j + 1}. å›¾ç‰‡: data URI (${mimeType}, ~${sizeKB}KB)`);
              } else {
                logger.info(`[${requestId}]       ${j + 1}. å›¾ç‰‡: è¿œç¨‹URL (${url.slice(0, 50)}...)`);
              }
            }
          }
        }

        // è®°å½•å·¥å…·è°ƒç”¨
        if (msg.tool_calls && msg.tool_calls.length > 0) {
          logger.info(`[${requestId}]     å·¥å…·è°ƒç”¨: ${msg.tool_calls.length} ä¸ª`);
          for (const toolCall of msg.tool_calls) {
            logger.info(`[${requestId}]       - ${toolCall.function?.name || 'æœªçŸ¥å‡½æ•°'}`);
          }
        }
      }
    }

    // éªŒè¯å¿…éœ€å­—æ®µ
    logger.info(`[${requestId}] ğŸ” å¼€å§‹éªŒè¯è¯·æ±‚å­—æ®µ`);

    if (!openaiRequest.model) {
      logger.warn(`[${requestId}] âŒ éªŒè¯å¤±è´¥: ç¼ºå°‘modelå­—æ®µ`);
      return new Response(
        JSON.stringify({
          error: {
            message: "ç¼ºå°‘å¿…éœ€å­—æ®µ: model",
            type: "invalid_request_error",
            param: "model",
          },
        }),
        {
          status: 400,
          headers: {
            "Content-Type": "application/json",
            ...getCorsHeaders()
          },
        }
      );
    }

    if (!openaiRequest.messages || !Array.isArray(openaiRequest.messages)) {
      logger.warn(`[${requestId}] âŒ éªŒè¯å¤±è´¥: messageså­—æ®µæ— æ•ˆ`);
      return new Response(
        JSON.stringify({
          error: {
            message: "ç¼ºå°‘æˆ–æ— æ•ˆçš„å¿…éœ€å­—æ®µ: messages",
            type: "invalid_request_error",
            param: "messages",
          },
        }),
        {
          status: 400,
          headers: {
            "Content-Type": "application/json",
            ...getCorsHeaders()
          },
        }
      );
    }

    // éªŒè¯æ¨¡å‹æ˜¯å¦å­˜åœ¨
    logger.info(`[${requestId}] ğŸ” éªŒè¯æ¨¡å‹: ${openaiRequest.model}`);
    const isValidModel = await modelService.isValidModel(openaiRequest.model);
    if (!isValidModel) {
      logger.warn(`[${requestId}] âŒ æ¨¡å‹éªŒè¯å¤±è´¥: ${openaiRequest.model} ä¸å­˜åœ¨`);
      return new Response(
        JSON.stringify({
          error: {
            message: `æ¨¡å‹ '${openaiRequest.model}' æœªæ‰¾åˆ°`,
            type: "invalid_request_error",
            param: "model",
          },
        }),
        {
          status: 400,
          headers: {
            "Content-Type": "application/json",
            ...getCorsHeaders()
          },
        }
      );
    }

    logger.info(`[${requestId}] âœ… æ‰€æœ‰éªŒè¯é€šè¿‡`);

    const chatRequestId = `chatcmpl-${crypto.randomUUID()}`;
    logger.info(`[${requestId}] ğŸ†” ç”ŸæˆèŠå¤©ID: ${chatRequestId}`);

    // å°†OpenAIè¯·æ±‚è½¬æ¢ä¸ºGeminiæ ¼å¼
    logger.info(`[${requestId}] ğŸ”„ å¼€å§‹è½¬æ¢è¯·æ±‚æ ¼å¼ (OpenAI -> Gemini)`);
    const geminiRequest = transformOpenAIRequestToGemini(openaiRequest, openaiRequest.model);
    logger.info(`[${requestId}] âœ… è¯·æ±‚æ ¼å¼è½¬æ¢å®Œæˆ`);

    if (openaiRequest.stream) {
      // å¤„ç†æµå¼å“åº”
      logger.info(`[${requestId}] ğŸŒŠ å¼€å§‹æµå¼è¯·æ±‚åˆ°Gemini API`);
      const geminiStream = await geminiClient.streamGenerateContent(openaiRequest.model, geminiRequest);
      const openaiStream = createGeminiToOpenAISSEStream(geminiStream, chatRequestId, openaiRequest.model);
      logger.info(`[${requestId}] âœ… æµå¼å“åº”å·²å»ºç«‹`);

      return new Response(openaiStream, {
        status: 200,
        headers: {
          "Content-Type": "text/event-stream",
          "Cache-Control": "no-cache",
          "Connection": "keep-alive",
          ...getCorsHeaders(),
        },
      });
    } else {
      // å¤„ç†éæµå¼å“åº”
      logger.info(`[${requestId}] ğŸ“¤ å‘é€è¯·æ±‚åˆ°Gemini API`);
      const geminiResponse = await geminiClient.generateContent(openaiRequest.model, geminiRequest);
      logger.info(`[${requestId}] ğŸ“¥ æ”¶åˆ°Gemini APIå“åº”`);

      logger.info(`[${requestId}] ğŸ”„ å¼€å§‹è½¬æ¢å“åº”æ ¼å¼ (Gemini -> OpenAI)`);
      const openaiResponse = transformGeminiResponseToOpenAI(geminiResponse, openaiRequest, chatRequestId);
      logger.info(`[${requestId}] âœ… å“åº”æ ¼å¼è½¬æ¢å®Œæˆ`);

      // è®°å½•å“åº”ç»Ÿè®¡
      if (openaiResponse.usage) {
        logger.info(`[${requestId}] ğŸ“Š Tokenä½¿ç”¨ç»Ÿè®¡:`);
        logger.info(`[${requestId}]   - æç¤ºToken: ${openaiResponse.usage.prompt_tokens}`);
        logger.info(`[${requestId}]   - å®ŒæˆToken: ${openaiResponse.usage.completion_tokens}`);
        logger.info(`[${requestId}]   - æ€»Token: ${openaiResponse.usage.total_tokens}`);
      }

      const responseContent = openaiResponse.choices?.[0]?.message?.content || '';
      const preview = responseContent.length > 100 ? responseContent.slice(0, 100) + '...' : responseContent;
      logger.info(`[${requestId}] ğŸ’¬ AIå›å¤é¢„è§ˆ: "${preview}"`);

      return new Response(JSON.stringify(openaiResponse), {
        status: 200,
        headers: {
          "Content-Type": "application/json",
          ...getCorsHeaders()
        },
      });
    }

  } catch (error) {
    logger.error(`[${requestId}] âŒ èŠå¤©è¡¥å…¨å¤„ç†é”™è¯¯:`, error);

    // è®°å½•é”™è¯¯è¯¦æƒ…
    const errorObj = error as { error?: { code?: number; message?: string }; message?: string };
    if (errorObj.error) {
      logger.error(`[${requestId}]   - é”™è¯¯ä»£ç : ${errorObj.error.code || 'æœªçŸ¥'}`);
      logger.error(`[${requestId}]   - é”™è¯¯ä¿¡æ¯: ${errorObj.error.message || 'æœªçŸ¥'}`);
    } else if (errorObj.message) {
      logger.error(`[${requestId}]   - é”™è¯¯ä¿¡æ¯: ${errorObj.message}`);
    }

    // å°†Geminié”™è¯¯è½¬æ¢ä¸ºOpenAIæ ¼å¼
    logger.info(`[${requestId}] ğŸ”„ è½¬æ¢é”™è¯¯æ ¼å¼ (Gemini -> OpenAI)`);
    const openaiError = transformGeminiErrorToOpenAI(error, "");
    const statusCode = errorObj?.error?.code || 500;

    logger.warn(`[${requestId}] ğŸ“¤ è¿”å›é”™è¯¯å“åº” (çŠ¶æ€ç : ${statusCode})`);

    return new Response(JSON.stringify(openaiError), {
      status: statusCode,
      headers: {
        "Content-Type": "application/json",
        ...getCorsHeaders()
      },
    });
  }
}

function getCorsHeaders(): Record<string, string> {
  const config = configManager.getConfig();
  return {
    "Access-Control-Allow-Origin": config.corsOrigin,
    "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
    "Access-Control-Allow-Headers": "Content-Type, Authorization, x-api-key",
    "Access-Control-Max-Age": "86400",
  };
}

// ä¸»æœåŠ¡å™¨å¯åŠ¨
async function main() {
  try {
    // åŠ è½½é…ç½®
    const config = await configManager.loadConfig();

    // é¢„è·å–å¯ç”¨æ¨¡å‹
    logger.info("æ­£åœ¨è·å–å¯ç”¨çš„Geminiæ¨¡å‹...");
    await modelService.getAvailableModels();

    logger.info(`æ­£åœ¨å¯åŠ¨Geminiåˆ°OpenAIå…¼å®¹APIæœåŠ¡å™¨...`);
    logger.info(`æœåŠ¡å™¨å°†åœ¨ç«¯å£ ${config.port} ä¸Šè¿è¡Œ`);
    logger.info(`CORSæº: ${config.corsOrigin}`);
    logger.info(`å·²åŠ è½½ ${config.geminiApiKeys.length} ä¸ªGemini APIå¯†é’¥`);
    logger.info(`å·²é…ç½® ${config.accessKeys.length} ä¸ªå‡†å…¥å¯†ç `);

    // ä½¿ç”¨Deno.serveå¯åŠ¨æœåŠ¡å™¨
    Deno.serve({ port: config.port }, handler);

  } catch (error) {
    console.error("å¯åŠ¨æœåŠ¡å™¨å¤±è´¥:", error);
    Deno.exit(1);
  }
}

// å¤„ç†ä¼˜é›…å…³é—­
Deno.addSignalListener("SIGINT", () => {
  logger.info("æ”¶åˆ°SIGINTä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...");
  Deno.exit(0);
});

// åªåœ¨éWindowsç³»ç»Ÿä¸Šç›‘å¬SIGTERM
if (Deno.build.os !== "windows") {
  Deno.addSignalListener("SIGTERM", () => {
    logger.info("æ”¶åˆ°SIGTERMä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...");
    Deno.exit(0);
  });
}

if (import.meta.main) {
  main();
}