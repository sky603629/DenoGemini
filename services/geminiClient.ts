import { GeminiRequest, GeminiResponse } from "../types/gemini.ts";
import { configManager, logger } from "../config/env.ts";
import { modelService } from "./modelService.ts";

export class GeminiClient {
  private async makeRequest(
    endpoint: string,
    request: GeminiRequest,
    stream: boolean = false,
    retryCount: number = 0
  ): Promise<Response> {
    const config = configManager.getConfig();
    const maxRetries = Math.min(config.maxRetries, configManager.getApiKeyCount());

    if (retryCount >= maxRetries) {
      throw new Error(`å·²è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•° (${maxRetries})`);
    }

    const apiKey = configManager.getApiKey(retryCount);
    const keyPreview = `${apiKey.slice(0, 8)}...${apiKey.slice(-4)}`;
    const url = `https://generativelanguage.googleapis.com/v1beta/${endpoint}?key=${apiKey}`;

    logger.info(`ğŸŒ Gemini APIè¯·æ±‚: ${endpoint} (ç¬¬ ${retryCount + 1} æ¬¡å°è¯•, å¯†é’¥: ${keyPreview})`);

    // è®°å½•è¯·æ±‚è¯¦æƒ…
    const hasImages = JSON.stringify(request).includes('"inlineData"');
    const messageCount = request.contents?.length || 0;
    logger.info(`ğŸ“‹ è¯·æ±‚å†…å®¹: ${messageCount} æ¡æ¶ˆæ¯${hasImages ? ', åŒ…å«å›¾åƒ' : ''}`);

    try {
      const controller = new AbortController();

      // æ ¹æ®æ¨¡å‹å’Œ max_tokens åŠ¨æ€è®¾ç½®è¶…æ—¶æ—¶é—´
      const isThinkingModel = endpoint.includes("2.5");
      const maxTokens = request.generationConfig?.maxOutputTokens || 1000;

      let timeoutMs = config.requestTimeout; // é»˜è®¤å€¼
      if (isThinkingModel && maxTokens > 10000) {
        timeoutMs = 120000; // 2 åˆ†é’Ÿï¼Œç”¨äºå¤§å‹è¯·æ±‚
      } else if (isThinkingModel) {
        timeoutMs = 60000;  // 1 åˆ†é’Ÿï¼Œç”¨äºæ€è€ƒæ¨¡å‹
      }

      const timeoutId = setTimeout(() => controller.abort(), timeoutMs);
      logger.debug(`è®¾ç½®è¯·æ±‚è¶…æ—¶æ—¶é—´: ${timeoutMs}ms (endpoint: ${endpoint}, maxTokens: ${maxTokens})`);

      const response = await fetch(url, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "User-Agent": "Deno-Gemini-Proxy/1.0",
          "Connection": "close", // é¿å…è¿æ¥å¤ç”¨é—®é¢˜
        },
        body: JSON.stringify(request),
        signal: controller.signal,
        // ç½‘ç»œé…ç½®ä¼˜åŒ–
        keepalive: false,
      });

      clearTimeout(timeoutId);

      logger.info(`âœ… Gemini APIå“åº”: ${response.status} ${response.statusText}`);

      // å¦‚æœé‡åˆ°é€Ÿç‡é™åˆ¶æˆ–æœåŠ¡å™¨é”™è¯¯ï¼Œå°è¯•ä¸‹ä¸€ä¸ªå¯†é’¥
      if (response.status === 429 || response.status >= 500) {
        if (retryCount < maxRetries - 1) {
          const delay = Math.min(Math.pow(2, retryCount) * 1000 + Math.random() * 1000, 10000);
          logger.warn(`âš ï¸ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç  ${response.status}ï¼Œ${delay}msåä½¿ç”¨ä¸‹ä¸€ä¸ªå¯†é’¥é‡è¯•...`);
          await new Promise(resolve => setTimeout(resolve, delay));
          return this.makeRequest(endpoint, request, stream, retryCount + 1);
        }
      }

      return response;
    } catch (error) {
      if ((error as Error).name === 'AbortError') {
        // é‡æ–°è®¡ç®—è¶…æ—¶æ—¶é—´ç”¨äºé”™è¯¯æ¶ˆæ¯
        const isThinkingModel = endpoint.includes("2.5");
        const maxTokens = request.generationConfig?.maxOutputTokens || 1000;
        let timeoutMs = config.requestTimeout;
        if (isThinkingModel && maxTokens > 10000) {
          timeoutMs = 120000;
        } else if (isThinkingModel) {
          timeoutMs = 60000;
        }
        throw new Error(`è¯·æ±‚è¶…æ—¶ï¼Œè¶…è¿‡ ${timeoutMs}ms`);
      }

      // å¦‚æœæ˜¯ç½‘ç»œé”™è¯¯ä¸”è¿˜æœ‰æ›´å¤šå¯†é’¥å¯å°è¯•
      if (retryCount < maxRetries - 1) {
        const delay = Math.min(Math.pow(2, retryCount) * 1000 + Math.random() * 1000, 10000); // æŒ‡æ•°é€€é¿ + éšæœºå»¶è¿Ÿï¼Œæœ€å¤§10ç§’
        logger.warn(`è¯·æ±‚å¤±è´¥ï¼Œé”™è¯¯: ${(error as Error).message}ï¼Œ${delay}msåä½¿ç”¨ä¸‹ä¸€ä¸ªå¯†é’¥é‡è¯•...`);
        await new Promise(resolve => setTimeout(resolve, delay));
        return this.makeRequest(endpoint, request, stream, retryCount + 1);
      }

      throw error;
    }
  }

  async generateContent(
    modelName: string,
    request: GeminiRequest
  ): Promise<GeminiResponse> {
    const normalizedModelName = modelService.normalizeModelName(modelName);
    const endpoint = `${normalizedModelName}:generateContent`;
    
    const response = await this.makeRequest(endpoint, request);
    
    if (!response.ok) {
      const errorBody = await response.json().catch(() => ({}));
      throw {
        error: {
          code: response.status,
          message: errorBody.error?.message || `HTTP ${response.status}: ${response.statusText}`,
          status: response.statusText,
          details: errorBody.error?.details || []
        }
      };
    }
    
    const responseData = await response.json();

    // è®°å½•è¯¦ç»†å“åº”ä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
    if (responseData.candidates && responseData.candidates.length > 0) {
      const candidate = responseData.candidates[0];
      const contentText = candidate.content?.parts?.[0]?.text || '';
      const contentLength = contentText.length;

      logger.info(`ğŸ“¥ Geminiå“åº”è¯¦æƒ…:`);
      logger.info(`   - å®ŒæˆåŸå› : ${candidate.finishReason || 'UNKNOWN'}`);
      logger.info(`   - å†…å®¹é•¿åº¦: ${contentLength} å­—ç¬¦`);
      logger.info(`   - å®Œæ•´å†…å®¹: "${contentText}"`);

      if (candidate.finishReason && candidate.finishReason !== "STOP") {
        logger.warn(`âš ï¸ Geminiéæ­£å¸¸å®Œæˆ: ${candidate.finishReason}`);

        // å¦‚æœæœ‰å®‰å…¨è¿‡æ»¤ä¿¡æ¯ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
        if (candidate.finishReason === "SAFETY" && candidate.safetyRatings) {
          logger.warn(`ğŸ›¡ï¸ å®‰å…¨è¿‡æ»¤è¯¦æƒ…: ${JSON.stringify(candidate.safetyRatings)}`);
        }

        // å¦‚æœæ˜¯MAX_TOKENSï¼Œè®°å½•tokenä½¿ç”¨æƒ…å†µ
        if (candidate.finishReason === "MAX_TOKENS") {
          logger.warn(`ğŸ“Š Tokené™åˆ¶è¯¦æƒ…: è¾“å‡ºè¢«æˆªæ–­`);
        }
      }

      // è®°å½•tokenä½¿ç”¨æƒ…å†µ
      if (responseData.usageMetadata) {
        logger.info(`ğŸ“Š Tokenä½¿ç”¨è¯¦æƒ…:`);
        logger.info(`   - è¾“å…¥Token: ${responseData.usageMetadata.promptTokenCount || 0}`);
        logger.info(`   - è¾“å‡ºToken: ${responseData.usageMetadata.candidatesTokenCount || 0}`);
        logger.info(`   - æ€»Token: ${responseData.usageMetadata.totalTokenCount || 0}`);
      }
    } else {
      logger.warn("âŒ Geminiå“åº”ä¸­æ²¡æœ‰candidates");
      logger.warn(`ğŸ” å®Œæ•´å“åº”: ${JSON.stringify(responseData)}`);
    }

    return responseData;
  }

  async streamGenerateContent(
    modelName: string,
    request: GeminiRequest
  ): Promise<ReadableStream<Uint8Array>> {
    const normalizedModelName = modelService.normalizeModelName(modelName);
    const endpoint = `${normalizedModelName}:streamGenerateContent`;
    
    const response = await this.makeRequest(endpoint, request, true);
    
    if (!response.ok) {
      const errorBody = await response.json().catch(() => ({}));
      throw {
        error: {
          code: response.status,
          message: errorBody.error?.message || `HTTP ${response.status}: ${response.statusText}`,
          status: response.statusText,
          details: errorBody.error?.details || []
        }
      };
    }
    
    if (!response.body) {
      throw new Error("æœªä»Gemini APIæ¥æ”¶åˆ°å“åº”ä½“");
    }
    
    return response.body;
  }
}

export const geminiClient = new GeminiClient();
