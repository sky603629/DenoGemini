# Gemini åˆ° OpenAI å…¼å®¹ API æœåŠ¡å™¨

åŸºäº Deno çš„ API æœåŠ¡å™¨ï¼Œä¸º Google çš„ Gemini API æä¾› OpenAI å…¼å®¹çš„ç«¯ç‚¹ï¼Œä½¿ç°æœ‰çš„åŸºäº OpenAI çš„åº”ç”¨ç¨‹åºèƒ½å¤Ÿæ— ç¼é›†æˆã€‚

## ç‰¹æ€§

- ğŸ”„ **å®Œå…¨ OpenAI å…¼å®¹**: æ”¯æŒ `/v1/chat/completions` å’Œ `/v1/models` ç«¯ç‚¹
- ğŸš€ **æµå¼æ”¯æŒ**: ä½¿ç”¨æœåŠ¡å™¨å‘é€äº‹ä»¶çš„å®æ—¶æµå¼å“åº”
- ğŸ–¼ï¸ **å¤šæ¨¡æ€æ”¯æŒ**: æ— ç¼å¤„ç†æ–‡æœ¬å’Œå›¾åƒè¾“å…¥
- ğŸ› ï¸ **å‡½æ•°è°ƒç”¨**: å®Œæ•´çš„å·¥å…·/å‡½æ•°è°ƒç”¨æ”¯æŒ
- ğŸ”‘ **API å¯†é’¥è´Ÿè½½å‡è¡¡**: åœ¨å¤šä¸ª Gemini API å¯†é’¥é—´è‡ªåŠ¨è½®æ¢
- ğŸ“Š **åŠ¨æ€æ¨¡å‹åˆ—è¡¨**: ç›´æ¥ä» Google è·å–å¯ç”¨æ¨¡å‹
- ğŸŒ **CORS æ”¯æŒ**: ä¸º Web åº”ç”¨ç¨‹åºæä¾›å¯é…ç½®çš„ CORS
- ğŸ”’ **é”™è¯¯å¤„ç†**: å…·æœ‰é‡è¯•é€»è¾‘çš„å…¨é¢é”™è¯¯å¤„ç†
- ğŸ“ **TypeScript**: å…·æœ‰å…¨é¢ç±»å‹å®šä¹‰çš„å®Œå…¨ç±»å‹åŒ–

## å¿«é€Ÿå¼€å§‹

### 1. å‰ææ¡ä»¶

- ç³»ç»Ÿä¸Šå®‰è£…äº† [Deno](https://deno.land/)
- ä» [Google AI Studio](https://makersuite.google.com/app/apikey) è·å– Google Gemini API å¯†é’¥

### 2. è®¾ç½®

1. å…‹éš†æˆ–ä¸‹è½½æ­¤é¡¹ç›®
2. å¤åˆ¶ `.env.example` åˆ° `.env`:
   ```bash
   cp .env.example .env
   ```
3. ç¼–è¾‘ `.env` å¹¶æ·»åŠ æ‚¨çš„é…ç½®:
   ```env
   # Gemini API å¯†é’¥
   GEMINI_API_KEYS=your_gemini_key_1,your_gemini_key_2

   # å‡†å…¥å¯†ç ï¼ˆå®¢æˆ·ç«¯éœ€è¦æä¾›ï¼‰
   ACCESS_KEYS=your_access_key_1,your_access_key_2
   ```

### 3. è¿è¡ŒæœåŠ¡å™¨

```bash
# å¼€å‘æ¨¡å¼ï¼ˆå¸¦è‡ªåŠ¨é‡è½½ï¼‰
deno task dev

# ç”Ÿäº§æ¨¡å¼
deno task start
```

æœåŠ¡å™¨é»˜è®¤å°†åœ¨ `http://localhost:8000` ä¸Šå¯åŠ¨ã€‚

## éƒ¨ç½²åˆ° Deno Deploy

æœ¬é¡¹ç›®ä¸“ä¸º Deno Deploy è®¾è®¡ã€‚è¯¦ç»†éƒ¨ç½²è¯´æ˜è¯·å‚è§ [DEPLOY.md](./DEPLOY.md)ã€‚

## ä½¿ç”¨æ–¹æ³•

### èŠå¤©è¡¥å…¨

```bash
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your_access_key" \
  -d '{
    "model": "gemini-1.5-pro",
    "messages": [
      {"role": "user", "content": "ä½ å¥½ï¼Œä½ æ€ä¹ˆæ ·ï¼Ÿ"}
    ],
    "stream": false
  }'
```

### æµå¼èŠå¤©

```bash
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your_access_key" \
  -d '{
    "model": "gemini-1.5-pro",
    "messages": [
      {"role": "user", "content": "ç»™æˆ‘è®²ä¸ªæ•…äº‹"}
    ],
    "stream": true
  }'
```

### åˆ—å‡ºæ¨¡å‹

```bash
curl -H "Authorization: Bearer your_access_key" \
  http://localhost:8000/v1/models
```

### å¤šæ¨¡æ€ï¼ˆè§†è§‰ï¼‰

```bash
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your_access_key" \
  -d '{
    "model": "gemini-1.5-pro",
    "messages": [
      {
        "role": "user",
        "content": [
          {"type": "text", "text": "ä½ åœ¨è¿™å¼ å›¾ç‰‡ä¸­çœ‹åˆ°äº†ä»€ä¹ˆï¼Ÿ"},
          {"type": "image_url", "image_url": {"url": "data:image/jpeg;base64,..."}}
        ]
      }
    ]
  }'
```

## Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `GEMINI_API_KEYS` | Comma-separated list of Gemini API keys | Required |
| `PORT` | Server port | `8000` |
| `CORS_ORIGIN` | CORS allowed origins | `*` |
| `LOG_LEVEL` | Logging level (debug/info/warn/error) | `info` |
| `MAX_RETRIES` | Maximum retry attempts per request | `3` |
| `REQUEST_TIMEOUT` | Request timeout in milliseconds | `30000` |

### Supported Models

The server dynamically fetches available models from Google's API. Common models include:

- `gemini-1.5-pro`
- `gemini-1.5-flash`
- `gemini-1.0-pro`
- And more...

Use the `/v1/models` endpoint to get the current list.

## OpenAI Compatibility

This server implements the following OpenAI API features:

### Supported Parameters

- `model` - Gemini model name
- `messages` - Conversation history
- `temperature` - Response randomness (0-2)
- `top_p` - Nucleus sampling parameter
- `max_tokens` - Maximum response length
- `stream` - Enable streaming responses
- `tools` - Function/tool definitions
- `tool_choice` - Tool selection strategy
- `stop` - Stop sequences
- `response_format` - JSON response format

### Message Types

- `system` - System instructions
- `user` - User messages (text and images)
- `assistant` - AI responses
- `tool` - Tool/function results

## Architecture

```
â”œâ”€â”€ main.ts                 # Main server entry point
â”œâ”€â”€ types/
â”‚   â”œâ”€â”€ openai.ts          # OpenAI API type definitions
â”‚   â””â”€â”€ gemini.ts          # Gemini API type definitions
â”œâ”€â”€ config/
â”‚   â””â”€â”€ env.ts             # Configuration and environment management
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ modelService.ts    # Model management and validation
â”‚   â””â”€â”€ geminiClient.ts    # Gemini API client with retry logic
â””â”€â”€ transformers/
    â”œâ”€â”€ openaiToGemini.ts  # Request transformation
    â”œâ”€â”€ geminiToOpenAI.ts  # Response transformation
    â””â”€â”€ streamTransformer.ts # Streaming response transformation
```

## Error Handling

The server provides comprehensive error handling:

- **Rate Limiting**: Automatic retry with different API keys
- **Network Errors**: Exponential backoff retry logic
- **Invalid Requests**: Proper validation with descriptive errors
- **API Errors**: Gemini errors transformed to OpenAI format

## Development

### Running Tests

```bash
deno test --allow-net --allow-env
```

### Code Formatting

```bash
deno fmt
```

### Linting

```bash
deno lint
```

## License

MIT License - see LICENSE file for details.

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## Support

For issues and questions:

1. Check the existing issues
2. Create a new issue with detailed information
3. Include logs and configuration (without API keys)
